{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DfE6-eG6b7u8"
   },
   "source": [
    "# [Project 4: Depth Estimation using Stereo](https://www.cc.gatech.edu/~hays/compvision/proj4_part1.pdf)    \n",
    "\n",
    "## **Part 1: Simple stereo by matching patches** \n",
    "\n",
    "(1) Random dot stereogram           \n",
    "(2) Similarity measure       \n",
    "(3) Disparity map    \n",
    "(4) Error profile analysis     \n",
    "(5) Real life stereo images           \n",
    "(6) Smoothing             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6mGh4uMcb7vD"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "id": "9uSfSEe6b7vD",
    "outputId": "b23b6602-9f86-4b64-e03e-d48129a84322"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from proj4_code.utils import load_image, PIL_resize, stereo_helper_fn, verify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rsepcaBRb7vF"
   },
   "source": [
    "## 1.1 Random dot stereogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It was once believed that in order to perceive depth, one must either match feature points (like SIFT) between left and right images, or rely upon clues such as shadows.\n",
    "\n",
    "A random dot stereogram eliminates all other depth cues, and hence proves that a  stereo setup is sufficient  to  get  an idea of the depth of the scene.   \n",
    "\n",
    "A  random  dot  stereogram  is  generated  by  the  following steps:\n",
    "1.  Create the left image with random dots at each pixel (0/1 values).\n",
    "2.  Create the right image as a copy of the left image.\n",
    "3.  Select a region in the right image and shift it horizontally.\n",
    "4.  Add a random pattern in the right image in the empty region created after the shift.\n",
    "\n",
    "In `part1a_random_stereogram.py`, you will implement `generate_random_stereogram()` to generate a randomdot stereogram for the given image size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N0-lmu0Rb7vG"
   },
   "outputs": [],
   "source": [
    "from proj4_code.part1a_random_stereogram import generate_random_stereogram\n",
    "from proj4_unit_tests.test_part1a_random_stereogram import test_generate_random_stereogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate the random stereogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PZy2joITb7vG"
   },
   "outputs": [],
   "source": [
    "# generate left and right images\n",
    "im_left, im_right = generate_random_stereogram(im_size=(51, 51, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OSX7e-Cob7vH",
    "outputId": "4852b251-acb3-4326-d43d-db47ecd5fc7e"
   },
   "outputs": [],
   "source": [
    "print('Test for random dot stereogram', verify(test_generate_random_stereogram))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the random stereogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the left and right images \n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 10))\n",
    "\n",
    "ax1.imshow(im_left, interpolation=None)\n",
    "ax1.title.set_text(\"Left image\")\n",
    "ax1.autoscale(False)\n",
    "ax1.set_axis_off()\n",
    "\n",
    "ax2.imshow(im_right, interpolation=None)\n",
    "ax2.title.set_text(\"Right image\")\n",
    "ax2.autoscale(False)\n",
    "ax2.set_axis_off()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nIB1Krirb7vI"
   },
   "source": [
    "## 1.2 Similarity measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute the difference between the two images, we will need to define some similarity measures.\n",
    "\n",
    "Two such measures we will use are:\n",
    "1. Sum of Squared Differences (SSD):\n",
    "\n",
    "    $SSD = \\sum_{i \\in [0,H], j \\in [0,W]} (A_{i,j} - B_{i,j}) ^ 2$\n",
    "    \n",
    "1. Sum of Absolute Differences (SAD):\n",
    "\n",
    "    $SAD = \\sum_{i \\in [0,H], j \\in [0,W]} |A_{i,j} - B_{i,j}|$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QRwuEurkb7vJ"
   },
   "source": [
    "Implement ```ssd_similarity_measure()``` and ```sad_similarity_measure()``` in ```part1b_similarity_measures.py``` to define the SSD and SAD measures.\n",
    "\n",
    "W'll use them to compare patches between the left and right images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FtYfvOrMb7vJ",
    "outputId": "3b3befca-d7d2-4e4f-8f67-064175e33515"
   },
   "outputs": [],
   "source": [
    "from proj4_unit_tests.test_part1b_similarity_measures import (\n",
    "  test_ssd_similarity_measure_values, \n",
    "  test_sad_similarity_measure_values, \n",
    "  test_similarity_measure_size_compatibility\n",
    ")\n",
    "\n",
    "print('Testing value for SAD measure', verify(test_sad_similarity_measure_values))\n",
    "print('Testing value for SSD measure', verify(test_ssd_similarity_measure_values))\n",
    "print('Testing input size compatibility for measures', verify(test_similarity_measure_size_compatibility))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F5PwjoFlb7vL"
   },
   "source": [
    "## 1.3 Disparity map "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2XWsmtOqb7vM"
   },
   "source": [
    "Implement ```calculate_disparity_map()``` in ```part1c_disparity_map.py``` to calculate the disparity value at each pixel by searching a small patch around a pixel from the left image in the right image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing\n",
    "\n",
    "Make sure your code works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9xR6Ml0eb7vM",
    "outputId": "982afa41-c907-440e-d4be-c83b4535ca36"
   },
   "outputs": [],
   "source": [
    "from proj4_unit_tests.test_part1c_disparity_map import (\n",
    "  test_disparity_deltafn_failure,\n",
    "  test_disparity_deltafn_success,\n",
    "  test_disparity_map_size,\n",
    "  test_disparity_random_stereogram,\n",
    "  test_disparity_translation_shift\n",
    ")\n",
    "\n",
    "print('Testing for disparity map on a delta function', verify(test_disparity_deltafn_failure))\n",
    "print('Testing for disparity map on a delta function', verify(test_disparity_deltafn_success))\n",
    "print('Testing disparity map size', verify(test_disparity_map_size))\n",
    "print('Testing random stereogram ouptut', verify(test_disparity_random_stereogram))\n",
    "print('Testing disparity on translation shift', verify(test_disparity_translation_shift))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize disparity maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll calculate and plot the images of disparity maps using SAD and SSD similarity function. \n",
    "\n",
    "You can tune the parameters and see the effect of them for different inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the docstring of `stereo_helper_fn`:\n",
    "\n",
    "This helper function will help us in calculating disparity maps for different parameters.\n",
    "It also plots the image.\n",
    "\n",
    "Please tune the parameters and see the effect of them for different inputs.\n",
    "\n",
    "Args:\n",
    "  - im_left: the left image\n",
    "  - im_right: the right image\n",
    "  - block_size: list of different block sizes to be used\n",
    "  - max_search_bound: the max horizontal displacement to look for the most similar patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2vEmA9MMb7vM",
    "outputId": "1d22ae32-1157-4aea-8b99-2d8df5d75473"
   },
   "outputs": [],
   "source": [
    "stereo_helper_fn(im_left, im_right, block_size = [3,5,9,13], max_search_bound=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hHfUIkm5b7vN"
   },
   "source": [
    "## 1.4 Error profile analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error profile is a visualization of the error function between the image that we're comparing to, and a patch in the search window of the other image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the images we'll be generating error profiles for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p6LsMgsYb7vO",
    "outputId": "8bbd2866-8f6c-48a8-cba6-fac4290ca743"
   },
   "outputs": [],
   "source": [
    "# load the image\n",
    "base_path = '../data/adirondack/'\n",
    "im_left = PIL_resize(load_image(base_path + 'im_left.png'), (0.1, 0.1))\n",
    "im_right = PIL_resize(load_image(base_path + 'im_right.png'), (0.1, 0.1))\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(10,10))\n",
    "\n",
    "ax1.imshow(im_left, interpolation=None)\n",
    "ax1.title.set_text('Left image')\n",
    "ax1.autoscale(False)\n",
    "ax1.set_axis_on()\n",
    "\n",
    "ax2.imshow(im_right, interpolation=None)\n",
    "ax2.title.set_text('Right image')\n",
    "ax2.autoscale(False)\n",
    "ax2.set_axis_on()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2rsa37o_b7vP"
   },
   "source": [
    "### Convex error profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convex error profiles have a distinct minimum, and correspond to a convex function, i.e. they are monotonically decreasing to the left of the minimum, and monotonically increasing to the right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mxol045wb7vN"
   },
   "source": [
    "Let's try to find different patches in the image which exhibit a close-to-convex error profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace the `None`s in the cell below to the top left corner of a 15x15 patch from the images that will generate a close-to-convex error profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KDEj5bxFb7vP",
    "outputId": "c3d890c4-4a59-4f0f-f697-99b1ac2e5f22",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract a patch of interest from the left image\n",
    "patch_size=15\n",
    "x_idx, y_idx = (None, None)\n",
    "patch_left_img = torch.tensor(im_left[x_idx:x_idx+patch_size+1, y_idx:y_idx+patch_size+1,:])\n",
    "plt.imshow(patch_left_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vu54LTw8b7vP",
    "outputId": "1060f692-0e2d-43fc-f63f-136772f4f932"
   },
   "outputs": [],
   "source": [
    "# get the search area in the right image\n",
    "max_search_bound = None # Adjust your search bound based on the (x_idx, y_idx) you chose\n",
    "search_area_right_img = torch.tensor(\n",
    "  im_right[x_idx:x_idx+patch_size+1, y_idx-max_search_bound:y_idx+patch_size+1,:]\n",
    ")\n",
    "plt.imshow(search_area_right_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the error profile\n",
    "\n",
    "The block below visualizes the error profile you generated for the patch you selected.\n",
    "\n",
    "For example:\n",
    "![Convex Error Profile](https://user-images.githubusercontent.com/16724970/111714792-d47d8f80-8828-11eb-9b65-eb0153691e35.png)\n",
    "\n",
    "In practice, the actual error profile may be slightly non-convex, but the overall effect remains the same.  Make sure that your error profile _looks_ convex, and answer the questions according to the patches you found that result in this kind of error profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cSsU4qGWb7vP",
    "outputId": "fcf86caa-95a6-4d12-f2a8-31127e26baa3"
   },
   "outputs": [],
   "source": [
    "from proj4_code.part1b_similarity_measures import sad_similarity_measure\n",
    "\n",
    "similarity_vals = np.array(\n",
    "  [sad_similarity_measure(patch_left_img, search_area_right_img[:,h_idx:h_idx+patch_size+1,:]) \n",
    "   for h_idx in range(search_area_right_img.shape[1]-patch_size-1)\n",
    "  ])\n",
    "plt.plot(similarity_vals)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iCRWsPwmb7vP"
   },
   "source": [
    "### Non-Convex error profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's visualize non-convex error profiles. Unlike convex profiles, they aren't monotonically increasing or decreasing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace the `None`s in the cell below to the top left corner of a 15x15 patch from the images that will generate a close-to-convex error profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zvslkazYb7vQ",
    "outputId": "2f675d8e-20d9-48f3-bcc5-9568372047a3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract a patch of interest from the left image\n",
    "patch_size=15\n",
    "x_idx, y_idx = (None, None) # replace with integers as before\n",
    "patch_left_img = torch.tensor(im_left[x_idx:x_idx+patch_size+1, y_idx:y_idx+patch_size+1,:])\n",
    "plt.imshow(patch_left_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZXk0Y8RFb7vQ",
    "outputId": "0809c89a-c293-44d4-b1f2-cc51d31ae62d"
   },
   "outputs": [],
   "source": [
    "# get the search area in the right image\n",
    "max_search_bound = None # set this value based on your (x_idx, y_idx) (needs to be an integer)\n",
    "search_area_right_img = torch.tensor(\n",
    "  im_right[x_idx:x_idx+patch_size+1, y_idx-max_search_bound:y_idx+patch_size+1,:]\n",
    ")\n",
    "plt.imshow(search_area_right_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing non-convex error profile\n",
    "\n",
    "Find patches that generate a highly non-convex error profile\n",
    "\n",
    "Example:\n",
    "![Non-Convex Error Profile](https://user-images.githubusercontent.com/16724970/111714795-d47d8f80-8828-11eb-94f3-be882116b78e.png)\n",
    "\n",
    "This example shows a non-convex error profile, but non convexity can be highly diverse! Make sure that your error profile _looks_ non-convex, and answer the questions according to the patches you found that result in this kind of error profile.\n",
    "\n",
    "Run the code below to generate the error profile for the patch you chose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0zCwDMPfb7vR",
    "outputId": "bbfc2940-f02e-4d98-ae17-a4486b66b6f8"
   },
   "outputs": [],
   "source": [
    "similarity_vals = np.array(\n",
    "  [sad_similarity_measure(patch_left_img, search_area_right_img[:,h_idx:h_idx+patch_size+1,:]) \n",
    "   for h_idx in range(search_area_right_img.shape[1]-patch_size-1)\n",
    "  ])\n",
    "plt.plot(similarity_vals)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TpmjY1OVb7vS"
   },
   "source": [
    "## 1.5 Real life stereo images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's generate disparity maps for real-life stereo images. The code blocks below will iterate through pairs of images from the dataset and calculate the disparity maps for images. You don't need to change anything; just run the code, include the visualizations in the report (wherever they are asked for) and answer the questions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JMvjD3x8b7vS"
   },
   "source": [
    "### Set 1: Adirondack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zUFcg1JIb7vS",
    "outputId": "ad4d4277-cc04-4fcf-fab3-b791cfc7b422",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_path = '../data/adirondack/'\n",
    "im_left = PIL_resize(load_image(base_path + 'im_left.png'), (0.1, 0.1))\n",
    "im_right = PIL_resize(load_image(base_path + 'im_right.png'), (0.1, 0.1))\n",
    "\n",
    "stereo_helper_fn(torch.tensor(im_left), torch.tensor(im_right), max_search_bound=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VCtAA9Y7b7vS"
   },
   "source": [
    "### Set 2: Bicycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SOvxyegQb7vS",
    "outputId": "d46675ec-0005-4aa4-de02-cd796a3db7f9"
   },
   "outputs": [],
   "source": [
    "base_path = '../data/bicycle/'\n",
    "im_left = PIL_resize(load_image(base_path + 'im_left.png'), (0.1, 0.1))\n",
    "im_right = PIL_resize(load_image(base_path + 'im_right.png'), (0.1, 0.1))\n",
    "\n",
    "stereo_helper_fn(torch.tensor(im_left), torch.tensor(im_right), block_size=[11], max_search_bound=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wPBUKQKDb7vT"
   },
   "source": [
    "### Set 3: Bowling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y1HRNP8bb7vT",
    "outputId": "4424025b-ac24-4981-9c58-af8a8439070d"
   },
   "outputs": [],
   "source": [
    "base_path = '../data/bowling/'\n",
    "im_left = PIL_resize(load_image(base_path + 'im_left.png'), (0.2, 0.2))\n",
    "im_right = PIL_resize(load_image(base_path + 'im_right.png'), (0.2, 0.2))\n",
    "\n",
    "stereo_helper_fn(torch.tensor(im_left), torch.tensor(im_right), block_size=[9], max_search_bound=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "typhSX2Cb7vU"
   },
   "source": [
    "### Set 4: Bowling 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sfet5qFzb7vU",
    "outputId": "1ff0a210-0358-4294-87e2-98e274fcd3cf"
   },
   "outputs": [],
   "source": [
    "base_path = '../data/bowling2/'\n",
    "im_left = PIL_resize(load_image(base_path + 'im_left.png'), (0.20, 0.20))\n",
    "im_right = PIL_resize(load_image(base_path + 'im_right.png'), (0.20, 0.20))\n",
    "\n",
    "stereo_helper_fn(torch.tensor(im_left), torch.tensor(im_right), block_size=[9], max_search_bound=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KNJmLjO2b7vU"
   },
   "source": [
    "### Set 5: Flowers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TrXscTfOb7vU",
    "outputId": "27afc627-fb09-4b4e-ce08-297762c4c9bd"
   },
   "outputs": [],
   "source": [
    "base_path = '../data/flowers/'\n",
    "im_left = PIL_resize(load_image(base_path + 'im_left.png'), (0.10, 0.10))\n",
    "im_right = PIL_resize(load_image(base_path + 'im_right.png'), (0.10, 0.10))\n",
    "\n",
    "stereo_helper_fn(torch.tensor(im_left), torch.tensor(im_right), block_size=[9], max_search_bound=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QYRpBU9Xb7vV"
   },
   "source": [
    "### Set 6: Stairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iG2xi9DSb7vV",
    "outputId": "6e1efc40-3151-4079-d820-f639b4383765"
   },
   "outputs": [],
   "source": [
    "base_path = '../data/stairs/'\n",
    "im_left = PIL_resize(load_image(base_path + 'im_left.jpg'), (1, 1))\n",
    "im_right = PIL_resize(load_image(base_path + 'im_right.jpg'), (1, 1))\n",
    "\n",
    "stereo_helper_fn(torch.tensor(im_left), torch.tensor(im_right), block_size = [3, 5, 7], max_search_bound=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5oksLKebb7vV"
   },
   "source": [
    "## 1.6 Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's smooth the images using semi-global matching (read the handout for more details on how it works).\n",
    "\n",
    "Implement the calculation of the cost-volume in `calculate_cost_volume` in `part1c_disparity_map.py`. You are encouraged to reuse any code you have written till now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we visualize the smoothed disparity maps, we need to ensure that the cost-volume calculation is error free. Run the block below to check whether you have any errors or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uYxJG4zrb7vV",
    "outputId": "2907c15a-63c1-4a3b-bdf8-ba5d01f59a1b"
   },
   "outputs": [],
   "source": [
    "from proj4_unit_tests.test_part1c_disparity_map import (\n",
    "  test_calculate_cost_volume\n",
    ")\n",
    "\n",
    "print('Testing for calculate_cost_volume', verify(test_calculate_cost_volume))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0O85xmXbb7vV",
    "outputId": "b9e278dd-f394-4e6f-8643-ddb46b72fad2"
   },
   "outputs": [],
   "source": [
    "from proj4_code.part1b_similarity_measures import ssd_similarity_measure, sad_similarity_measure\n",
    "from scipy import ndimage\n",
    "from semiglobalmatching.sgm import sgm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize smoothed disparity maps\n",
    "\n",
    "We'll make use of the `calculate_cost_volume` function you implemented to perform semi-global matching, and visualize the smoothed disparity maps.\n",
    "\n",
    "Observe the differences between the disparity maps you visualized earlier, and their smoothed versions, and answer the questions in your report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZI1wMK5db7vW"
   },
   "outputs": [],
   "source": [
    "# load the image\n",
    "# feel free to try other pairs, but you may need to fix the scaling per pair\n",
    "base_path = '../data/adirondack/'\n",
    "im_left = PIL_resize(load_image(base_path + 'im_left.png'), (0.10, 0.10))\n",
    "im_right = PIL_resize(load_image(base_path + 'im_right.png'), (0.10, 0.10))\n",
    "\n",
    "# base_path = '../data/bicycle/'\n",
    "# im_left = PIL_resize(load_image(base_path + 'im_left.png'), (0.1, 0.1))\n",
    "# im_right = PIL_resize(load_image(base_path + 'im_right.png'), (0.1, 0.1))\n",
    "\n",
    "# base_path = '../data/bowling/'\n",
    "# im_left = PIL_resize(load_image(base_path + 'im_left.png'), (0.2, 0.2))\n",
    "# im_right = PIL_resize(load_image(base_path + 'im_right.png'), (0.2, 0.2))\n",
    "\n",
    "# base_path = '../data/bowling2/'\n",
    "# im_left = PIL_resize(load_image(base_path + 'im_left.png'), (0.20, 0.20))\n",
    "# im_right = PIL_resize(load_image(base_path + 'im_right.png'), (0.20, 0.20))\n",
    "\n",
    "# base_path = '../data/flowers/'\n",
    "# im_left = PIL_resize(load_image(base_path + 'im_left.png'), (0.10, 0.10))\n",
    "# im_right = PIL_resize(load_image(base_path + 'im_right.png'), (0.10, 0.10))\n",
    "\n",
    "# base_path = '../data/stairs/'\n",
    "# im_left = PIL_resize(load_image(base_path + 'im_left.jpg'), (1, 1))\n",
    "# im_right = PIL_resize(load_image(base_path + 'im_right.jpg'), (1, 1))\n",
    "\n",
    "# show the img\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 10))\n",
    "ax1.imshow(im_left, interpolation=None)\n",
    "ax1.title.set_text(\"Left image\")\n",
    "ax1.autoscale(False)\n",
    "ax1.set_axis_off()\n",
    "ax2.imshow(im_right, interpolation=None)\n",
    "ax2.title.set_text(\"Right image\")\n",
    "ax2.autoscale(False)\n",
    "ax2.set_axis_off()\n",
    "plt.show()\n",
    "\n",
    "# calculate the disparity map with SGM, the last argument is max disparity to consider\n",
    "disparity_map = sgm(im_left,im_right, \"result\", 30, sad_similarity_measure, 9)\n",
    "result = ndimage.median_filter(disparity_map, size=5)\n",
    "plt.figure()\n",
    "plt.imshow(result, cmap='jet', interpolation='nearest')\n",
    "plt.title('Disparity map')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "simple_stereo.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
